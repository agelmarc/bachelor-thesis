An atomic nucleus consists of subnuclear particles called nucleons, which in turn consist of smaller elementary particles called quarks. As a result of the strong nuclear force, binding potentials of a nucleus are of very complex nature which cannot be described by simple radially symmetric potentials. Since the interactions between nucleons are not yet fully understood, the formulated quantummechanical many-body problem of a nucleus is an active research area in physics. Modern approaches to solving this problem include the so-called \textit{ab inito} No-Core Shell Model (NCSM), which provides quantifiable approximations by using controlled truncations of the full nuclear Hilbert space. From the systematic increasement of these truncations and, thus, the corresponding model-spaces, converging series emerge whose limits are the solutions in the full Hilbert space.

As NCSM calculations get more computationally expensive for larger model-space sizes and heavier nuclei, the actual ground-state energy cannot be directly constructed from the resulting energy sequences. To estimate the ground-state energy out of the approximate energies coming from NCSM calculations, extrapolation methods have to be used. Classical extrapolation strategies include exponential function fits on the converging sequences. In this thesis, we investigate another approach to this extrapolation by using artificial neural networks (ANN). ANN's are general data processing constructs that can model complex connections in data. For that, the networks have to be trained on a dataset with known predictions.

There have been various applications in extrapolating NCSM sequences. This includes the work of Negoita et. al \cite{neg} and of Jiang et. al \cite{2019}. In this thesis, we aim to reconstruct and modify the extrapolation framework which was developed by Cedric Wenz \cite{cedric} and directly extrapolates an absolute ground-state energy by taking untransformed NCSM sequences for multiple oscillator frequencies into account. Based on this absolute-based extrapolation framework, we further develop a second framework which is based on extrapolating sequences of differences between two results of consecutive model-space sizes. The networks get trained by NCSM datasets for the nuclei \n{2}{H}, \n{3}{H} and \n{4}{He}.

For both frameworks, the extrapolation quality gets analyzed in dependence on the model-space size of the evaluation data, as well as the preconditioning of the used Hamiltonian using the Similarity Renormalization Group (SRG) transformation, by evaluating the nuclei used in training with different models for the nuclear interaction. Afterwards, we are going to discuss the influence of two different modifications in the training data set on the extrapolations.

In a final application, we will discuss the extrapolation of both frameworks by evaluating the nucleus \n{6}{Li}, which was previously unseen by the networks.
We will further be drawing a conclusion about the two extrapolation frameworks as well as the training set modifications and state a final extrapolation result for this nucleus.

Lastly, we want to briefly outlay two general ideas for the extrapolation of NCSM calculations by preselecting the input data.
