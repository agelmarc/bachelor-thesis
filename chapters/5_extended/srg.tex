In our second training mode, we want to take another approach to our extrapolation framework as the $N_\mathrm{max}$-limitation training mode. As we have already seen, a SRG evolution of the Hamiltonian results in a faster convergence of the NCSM sequences. Taking this into account, we can also try to train the networks only using NCSM calculations with SRG evolved Hamiltonians using a minimum flow parameter of \srg{0.04}. In doing this, we hope to achieve a more uniform and stronger convergence in the different sequences in the training, such that the networks do not have to extrapolate as much as with unconverged sequences. This will also be useful for the later uses of the extrapolation on heavier nuclei, as an SRG evolution can always be done.
