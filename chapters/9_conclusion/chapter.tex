In this thesis, we have formulated and analyzed two different extrapolation frameworks to predict the ground-state energy out of NCSM calculations using artificial neural networks.

In our first extrapolation framework (absolute-based), the input data consists of three different sequences of four NCSM calculations for consecutive $N_\mathrm{max}$ values. The output of the networks is then directly identified as the network prediction for the ground-state energy. In our second extrapolation framework (difference-based), we took the same sequences as described above and computed the difference of consecutive $N_\mathrm{max}$ values, resulting in three sequences of three values. In this case, the output is identified as the difference of the prediction and the mean absolute value at the largest $N_\mathrm{max}$. In both frameworks, the networks are trained according to that identification by the nuclei \n{2}{H}, \n{3}{H} and \n{4}{He} using chiral interactions of various leading orders and cutoffs for two-body interactions \cite{entemmachleidt} as well as two- and three-body interactions \cite{HUTHER2020135651}. Furthermore, the Hamiltonians were SRG evolved for flow parameters between \srg{0.04} and \srg{0.08}. To analyze the frameworks, we used the same nuclei with a semi-local momentum-space regulated N$^{2}$LO interaction with two-body interactions and a cutoff at \SI{450}{\mega\electronvolt} which was SRG evolved using a flow parameter of \srg{0.04} and \srg{0.08}.

First, we have analyzed the extrapolation behaviour of the absolute-based framework in dependency on the maximum $N_\mathrm{max}$ value of the used evaluation sequences and the SRG flow parameter. We have found two different systematic behaviours of the extrapolations for the nuclei \n{3}{H}, \n{4}{He} and the nucleus \n{2}{H}. The extrapolations for the nuclei \n{3}{H} and \n{4}{He} were generally too low and the networks corrected them to higher values with higher $N_\mathrm{max}$ values. For \n{2}{H}, the extrapolations were too high at low $N_\mathrm{max}$ values and got lower for higher $N_\mathrm{max}$. We have defined the variational boundary condition, which was satisfied for the extrapolations on \n{3}{H} and \n{4}{He} but not on \n{2}{H}. The classical extrapolations consisting of exponential function fits generally outperformed our framework on the more converged sequences of \n{3}{H} and \n{4}{He}, but were comparable for \n{2}{H}.

Before analyzing the difference-based framework, we discussed two different modifications on the training set for the absolute-based framework. The first modification consisted of restricting the training samples to a maximum $N_\mathrm{max}$ of $24$, while the second modification restricted the used interactions to SRG evolved interactions with a minimum flow parameter of \srg{0.04}. We have introduced the conditions of prediction consistency and reasonability to assess the two training modes. We have found that the $N_\mathrm{max}$-limitation training mode did not conform to those two conditions, while the SRG-filter training mode did. In general, the SRG-filter training mode produced the most promising extrapolations for our training nuclei.

After that, we have analyzed the previously introduced training modes in our difference-based framework. We have found that all of the training modes, as well as the unmodified training produced much more reasonable results for the nuclei. Here, the training modes did not significantly improve the value of the prediction but rather the uncertainty. As in the absolute-based framework, the SRG-filter training mode showed the most reasonable and consistent results.

In a real use-case application of our extrapolation framework using the nucleus \n{6}{Li}, which was previously unseen by the networks, we have seen that the SRG-filter training mode produced unreasonably high predictions while the $N_\mathrm{max}$-limitation training mode did not provide sufficiently different results to the unmodified training mode. The predictions of the unmodified training produced more consistent results than the classical extrapolations accross the $N_\mathrm{max}$ values. In a final decision using the insights of the extrapolation for all four nuclei, we have found the difference-based extrapolation framework together with the unmodified training to produce the overall most reasonable results.

Finally, we have looked into two different ideas that could further develop the difference-based framework to yield better results. The first idea included a new training modification, where frequencies were only included in the training if they are bigger or smaller than the frequency which results in the best convergence. The networks were thus trained to model the long or the short range of the nuclear interaction, respectively. We have found the high frequency filter training mode to produce more consistent and more precise results, although this idea has to be further examined for more nuclei. Secondly, we have persued the idea of manually selecting the frequencies for the evaluation data by choosing a selection rule. This results in better extrapolations, but limits the generality of our extrapolation framework.
